{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.180:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1578843109447)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.types._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\n",
    "// https://towardsdatascience.com/python-pandas-vs-scala-how-to-handle-dataframes-part-ii-d3e5efe8287d\n",
    "// https://towardsdatascience.com/python-vs-scala-a-comparison-of-the-basic-commands-fae23b3ede23\n",
    "// https://docs.databricks.com/data/data-sources/read-csv.html\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1174644a\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Basics\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.7252249717712402 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "firedep: org.apache.spark.sql.DataFrame = [Call Number: string, Unit ID: string ... 32 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val firedep =  spark.read\n",
    "              .format(\"csv\")\n",
    "              .option(\"header\", \"true\") //first line in file has headers\n",
    "              .option(\"mode\", \"DROPMALFORMED\")\n",
    "              .load(\"/Users/furqan/Python/Spark_Temp/Fire_Department_Calls_for_Service.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------+--------------+----------+----------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------------------+----------------------+-------------------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-----------------------------------------+-------------+\n",
      "|Call Number|Unit ID|Incident Number|Call Type     |Call Date |Watch Date|Received DtTm         |Entry DtTm            |Dispatch DtTm         |Response DtTm         |On Scene DtTm         |Transport DtTm|Hospital DtTm|Call Final Disposition|Available DtTm        |Address                  |City         |Zipcode of Incident|Battalion|Station Area|Box |Original Priority|Priority|Final Priority|ALS Unit|Call Type Group|Number of Alarms|Unit Type|Unit sequence in call dispatch|Fire Prevention District|Supervisor District|Neighborhooods - Analysis Boundaries|Location                                 |RowID        |\n",
      "+-----------+-------+---------------+--------------+----------+----------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------------------+----------------------+-------------------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-----------------------------------------+-------------+\n",
      "|192910017  |E11    |19125164       |Alarms        |10/18/2019|10/17/2019|10/18/2019 12:03:52 AM|10/18/2019 12:06:59 AM|10/18/2019 12:07:05 AM|10/18/2019 12:08:28 AM|10/18/2019 12:11:10 AM|null          |null         |Fire                  |10/18/2019 12:33:57 AM|24TH ST/VALENCIA ST      |San Francisco|94110              |B06      |11          |5525|3                |3       |3             |true    |Alarm          |1               |ENGINE   |1                             |6                       |9                  |Mission                             |(37.75210364574824, -122.42066480228367) |192910017-E11|\n",
      "|192910018  |B10    |19125165       |Alarms        |10/18/2019|10/17/2019|10/18/2019 12:05:56 AM|10/18/2019 12:07:27 AM|10/18/2019 12:09:49 AM|null                  |null                  |null          |null         |Other                 |10/18/2019 12:10:14 AM|3300 Block of 23RD ST    |San Francisco|94110              |B06      |11          |0552|3                |3       |3             |false   |Alarm          |1               |CHIEF    |1                             |6                       |9                  |Mission                             |(37.75368162954947, -122.4202535645237)  |192910018-B10|\n",
      "|192910018  |T07    |19125165       |Alarms        |10/18/2019|10/17/2019|10/18/2019 12:05:56 AM|10/18/2019 12:07:27 AM|10/18/2019 12:09:49 AM|null                  |null                  |null          |null         |Other                 |10/18/2019 12:10:14 AM|3300 Block of 23RD ST    |San Francisco|94110              |B06      |11          |0552|3                |3       |3             |false   |Alarm          |1               |TRUCK    |3                             |6                       |9                  |Mission                             |(37.75368162954947, -122.4202535645237)  |192910018-T07|\n",
      "|192910025  |B04    |19125166       |Alarms        |10/18/2019|10/17/2019|10/18/2019 12:09:02 AM|10/18/2019 12:09:02 AM|10/18/2019 12:09:02 AM|10/18/2019 12:09:02 AM|10/18/2019 12:09:02 AM|null          |null         |Fire                  |10/18/2019 12:21:52 AM|3300 Block of FILLMORE ST|San Francisco|94123              |B04      |16          |3554|3                |3       |3             |false   |Alarm          |1               |CHIEF    |1                             |4                       |2                  |Marina                              |(37.80034056356869, -122.43607739030332) |192910025-B04|\n",
      "|192910034  |E01    |19125167       |Structure Fire|10/18/2019|10/17/2019|10/18/2019 12:12:39 AM|10/18/2019 12:12:39 AM|10/18/2019 12:12:48 AM|10/18/2019 12:13:52 AM|10/18/2019 12:16:16 AM|null          |null         |Fire                  |10/18/2019 12:16:25 AM|7TH ST/MISSION ST        |San Francisco|94103              |B02      |01          |2315|3                |3       |3             |true    |Alarm          |1               |ENGINE   |1                             |2                       |6                  |South of Market                     |(37.779211684542084, -122.41093657380038)|192910034-E01|\n",
      "+-----------+-------+---------------+--------------+----------+----------+----------------------+----------------------+----------------------+----------------------+----------------------+--------------+-------------+----------------------+----------------------+-------------------------+-------------+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+------------------------------------+-----------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firedep.show(5, false)\n",
    "//firedep.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(ReceivedDtTm,StringType,true), StructField(EntryDtTm,StringType,true), StructField(DispatchDtTm,StringType,true), StructField(ResponseDtTm,StringType,true), StructField(OnSceneDtTm,StringType,true), StructField(TransportDtTm,StringType,true), StructField(HospitalDtTm,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(ZipcodeOfIncident..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = new StructType()\n",
    "       .add(\"CallNumber\", IntegerType, true)\n",
    "       .add(\"UnitID\", StringType, true)\n",
    "       .add(\"IncidentNumber\", IntegerType, true)\n",
    "       .add(\"CallType\", StringType, true)\n",
    "       .add(\"CallDate\", StringType, true)\n",
    "       .add(\"WatchDate\", StringType, true)\n",
    "       .add(\"ReceivedDtTm\", StringType, true)\n",
    "       .add(\"EntryDtTm\", StringType, true)\n",
    "       .add(\"DispatchDtTm\", StringType, true)\n",
    "       .add(\"ResponseDtTm\", StringType, true)\n",
    "       .add(\"OnSceneDtTm\", StringType, true)\n",
    "       .add(\"TransportDtTm\", StringType, true)\n",
    "       .add(\"HospitalDtTm\", StringType, true)\n",
    "       .add(\"CallFinalDisposition\", StringType, true)\n",
    "       .add(\"AvailableDtTm\", StringType, true)\n",
    "       .add(\"Address\", StringType, true)\n",
    "       .add(\"City\", StringType, true)\n",
    "       .add(\"ZipcodeOfIncident\",IntegerType, true)\n",
    "       .add(\"Battalion\",StringType, true)\n",
    "       .add(\"StationArea\",StringType, true)\n",
    "       .add(\"Box\",StringType, true)\n",
    "       .add(\"OriginalPriority\",StringType, true)\n",
    "       .add(\"Priority\", StringType, true)\n",
    "       .add(\"FinalPriority\", IntegerType, true)\n",
    "       .add(\"ALSUnit\", BooleanType, true)\n",
    "       .add(\"CallTypeGroup\", StringType, true)\n",
    "       .add(\"NumberOfAlarms\", IntegerType, true)\n",
    "       .add(\"UnitType\", StringType, true)\n",
    "       .add(\"UnitSequenceInCallDispatch\", IntegerType, true)\n",
    "       .add(\"FirePreventionDistrict\", StringType, true)\n",
    "       .add(\"SupervisorDistrict\", StringType, true)\n",
    "       .add(\"NeighborhooodsDistrict\", StringType, true)\n",
    "       .add(\"Location\", StringType, true)\n",
    "       .add(\"RowID\", StringType, true)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.21938419342041016 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "firedep: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 32 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val firedep = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .schema(schema)\n",
    "  .load(\"/Users/furqan/Python/Spark_Temp/Fire_Department_Calls_for_Service.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- ReceivedDtTm: string (nullable = true)\n",
      " |-- EntryDtTm: string (nullable = true)\n",
      " |-- DispatchDtTm: string (nullable = true)\n",
      " |-- ResponseDtTm: string (nullable = true)\n",
      " |-- OnSceneDtTm: string (nullable = true)\n",
      " |-- TransportDtTm: string (nullable = true)\n",
      " |-- HospitalDtTm: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ZipcodeOfIncident: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumberOfAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- NeighborhooodsDistrict: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firedep.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+--------------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------+------------------+---------+-----------------+------------------+------------------+------------------+-------------------+--------------------+-------------------+--------+--------------------------+----------------------+------------------+----------------------+--------------------+--------------+\n",
      "|summary|          CallNumber|            UnitID|      IncidentNumber|            CallType|  CallDate| WatchDate|        ReceivedDtTm|           EntryDtTm|        DispatchDtTm|        ResponseDtTm|         OnSceneDtTm|       TransportDtTm|        HospitalDtTm|CallFinalDisposition|       AvailableDtTm|        Address|       City| ZipcodeOfIncident|Battalion|      StationArea|               Box|  OriginalPriority|          Priority|      FinalPriority|       CallTypeGroup|     NumberOfAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|NeighborhooodsDistrict|            Location|         RowID|\n",
      "+-------+--------------------+------------------+--------------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------+------------------+---------+-----------------+------------------+------------------+------------------+-------------------+--------------------+-------------------+--------+--------------------------+----------------------+------------------+----------------------+--------------------+--------------+\n",
      "|  count|             5144933|           5144933|             5144933|             5144933|   5144933|   5144933|             5144933|             5144933|             5144933|             4731571|             3976402|             1354352|             1219667|             5144933|             5067994|        5144933|    5137139|           5130694|  5144933|          5142603|           5144502|           5119404|           5144930|            5144933|             2338424|            5144933| 5144933|                   5144870|               5144933|           5144933|               5144933|             5144933|       5144933|\n",
      "|   mean|1.0452980439042258E8|  75.1004358540637|1.0330587302363316E7|                null|      null|      null|                null|                null|                null|                null|                null|                null|                null|                null|                null|           null|       null| 94113.50492837811|     null|18.08897692154346|4078.3620324747476|2.7605420147220032| 2.741932032695544|  2.787688974764103|                null| 1.0054086224252095|    null|         2.165125455064948|    4.7363222721674845|5.9762283142080115|                  null|                null|          null|\n",
      "| stddev| 5.694029816593383E7|12.863059987150093|  5703928.2673258195|                null|      null|      null|                null|                null|                null|                null|                null|                null|                null|                null|                null|           null|       null|10.207214407073971|     null|14.51858830174029| 2370.489875149915|0.5042920739831711|0.5152759026508116|0.40894386693529283|                null|0.09963311637299194|    null|         2.142986047721931|    2.9212485414672034| 2.715766483312575|                  null|                null|          null|\n",
      "|    min|             1030101|                27|               30612|      Administrative|01/01/2001|01/01/2001|01/01/2001 01:00:...|01/01/2001 01:01:...|01/01/2001 01:01:...|01/01/2001 01:01:...|01/01/2001 01:00:...|01/01/2001 01:04:...|01/01/2001 01:04:...|Against Medical A...|01/01/2001 01:00:...|***CAMP FIRE***|         AI|             94102|       3E|               01|              0123|                 1|                 1|                  2|               Alarm|                  1| AIRPORT|                         1|                     1|                 1|  Bayview Hunters P...|(37.616882323925,...| 001030101-E18|\n",
      "|    max|           193414308|               UU1|            19147737|Watercraft in Dis...|12/31/2018|12/31/2018|12/31/2018 12:58:...|12/31/2018 12:59:...|12/31/2018 12:58:...|12/31/2018 12:57:...|12/31/2018 12:59:...|12/31/2018 12:58:...|12/31/2018 12:59:...|    Unable to Locate|12/31/2018 12:59:...|ZOE ST/WELSH ST|Yerba Buena|             94158|      B99|               F3|              AI02|                 I|                 I|                  3|Potentially Life-...|                  5|   TRUCK|                        83|                  None|              None|      Western Addition|(37.8544643401171...|193414308-QRV1|\n",
      "+-------+--------------------+------------------+--------------------+--------------------+----------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+-----------+------------------+---------+-----------------+------------------+------------------+------------------+-------------------+--------------------+-------------------+--------+--------------------------+----------------------+------------------+----------------------+--------------------+--------------+\n",
      "\n",
      "Time: 119.68450593948364 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "firedep.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter DataFrame to get Column or DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Class[_ <: org.apache.spark.sql.Column] = class org.apache.spark.sql.Column\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//https://stackoverflow.com/questions/39061465/how-to-display-the-results-brough-from-column-functions-using-spark-scala-like-w\n",
    "//https://spark.apache.org/docs/1.6.0/api/java/org/apache/spark/sql/Column.html\n",
    "//firedep.select(firedep(\"CallNumber\")).show()\n",
    "firedep(\"CallNumber\").getClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Class[_ <: org.apache.spark.sql.DataFrame] = class org.apache.spark.sql.Dataset\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firedep.select(\"CallNumber\").getClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|CallNumber|NumberOfAlarms|\n",
      "+----------+--------------+\n",
      "| 192910017|             1|\n",
      "| 192910018|             1|\n",
      "| 192910018|             1|\n",
      "| 192910025|             1|\n",
      "| 192910034|             1|\n",
      "+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firedep.select($\"CallNumber\", $\"NumberOfAlarms\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DF Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: identifier expected but integer literal found.",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: identifier expected but integer literal found.",
      "firedep.select($\"CallNumber\", $\"NumberOfAlarms\").head()[0]",
      "                                                        ^",
      ""
     ]
    }
   ],
   "source": [
    "firedep.select($\"CallNumber\", $\"NumberOfAlarms\").head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null_df: org.apache.spark.sql.DataFrame = [Acct: string, month: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val null_df = spark.read.format(\"csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"NullData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   B|    3|   20|  null|\n",
      "|   C|    1| 1000|   100|\n",
      "|   C|    2|   10|  null|\n",
      "|   C|    3| null|  null|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   C|    1| 1000|   100|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NA with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   B|    3|   20|  null|\n",
      "|   C|    1| 1000|   100|\n",
      "|   C|    2|   10|  null|\n",
      "|   C|    3| null|  null|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Each row must contain atleast 2 non null values to be not dropped\n",
    "null_df.na.drop(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: Class[_ <: org.apache.spark.sql.DataFrame] = class org.apache.spark.sql.Dataset\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df.select(\"Debit\").getClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   B|    3|   20|  null|\n",
      "|   C|    1| 1000|   100|\n",
      "|   C|    2|   10|  null|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// define subset to drop\n",
    "null_df.filter(null_df.col(\"Debit\").isNotNull).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   B|    3|   20|  null|\n",
      "|   C|    1| 1000|   100|\n",
      "|   C|    2|   10|  null|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_df.na.drop(how=\"any\",Seq(\"Debit\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+------+\n",
      "|Acct|month|Debit|Credit|\n",
      "+----+-----+-----+------+\n",
      "|   A|    1|  100|   200|\n",
      "|   A|    2|  200|   200|\n",
      "|   A|    3|  300|    10|\n",
      "|   B|    1|   10|   200|\n",
      "|   C|    1| 1000|   100|\n",
      "+----+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_df.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "converted_null_df: org.apache.spark.sql.DataFrame = [Acct: string, month: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var converted_null_df = null_df.withColumn(\"Debit\", col(\"Debit\").cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "converted_null_df: org.apache.spark.sql.DataFrame = [Acct: string, month: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_null_df = converted_null_df.withColumn(\"Credit\", col(\"Credit\").cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Acct: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- Debit: integer (nullable = true)\n",
      " |-- Credit: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted_null_df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pvt_df: org.apache.spark.sql.DataFrame = [Acct: string, 1: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var pvt_df = converted_null_df.groupBy(\"Acct\").pivot(\"Month\").sum(\"Debit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+\n",
      "|Acct|   1|   2|   3|\n",
      "+----+----+----+----+\n",
      "|   B|  10|null|  20|\n",
      "|   C|1000|  10|null|\n",
      "|   A| 100| 200| 300|\n",
      "+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pvt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Acct: string (nullable = true)\n",
      " |-- 1_sum(Debit): long (nullable = true)\n",
      " |-- 1_sum(Credit): long (nullable = true)\n",
      " |-- 2_sum(Debit): long (nullable = true)\n",
      " |-- 2_sum(Credit): long (nullable = true)\n",
      " |-- 3_sum(Debit): long (nullable = true)\n",
      " |-- 3_sum(Credit): long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivoted_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pivoted_data: org.apache.spark.sql.DataFrame = [Acct: string, 1_sum(Debit): bigint ... 5 more fields]\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var pivoted_data = converted_null_df.groupBy(\"Acct\").pivot(\"Month\").sum(\"Debit\", \"Credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "renamed_conv_null_df: org.apache.spark.sql.DataFrame = [Acct: string, M1D: bigint ... 5 more fields]\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var renamed_conv_null_df = pivoted_data.withColumnRenamed(\"1_sum(Debit)\", \"M1D\") \n",
    "                          .withColumnRenamed(\"1_sum(Credit)\", \"M1C\") \n",
    "                          .withColumnRenamed(\"2_sum(Debit)\", \"M2D\") \n",
    "                          .withColumnRenamed(\"2_sum(Credit)\", \"M2C\") \n",
    "                          .withColumnRenamed(\"3_sum(Debit)\", \"M3D\") \n",
    "                          .withColumnRenamed(\"3_sum(Credit)\", \"M3C\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+----+----+----+----+\n",
      "|Acct| M1D|M1C| M2D| M2C| M3D| M3C|\n",
      "+----+----+---+----+----+----+----+\n",
      "|   B|  10|200|null|null|  20|null|\n",
      "|   C|1000|100|  10|null|null|null|\n",
      "|   A| 100|200| 200| 200| 300|  10|\n",
      "+----+----+---+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "renamed_conv_null_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column and fillna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: illegal start of simple expression",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: illegal start of simple expression",
      "renamed_conv_null_df = renamed_conv_null_df.fillna(0, subset=[\"M2C\"])",
      "                                                             ^",
      ""
     ]
    }
   ],
   "source": [
    "renamed_conv_null_df = renamed_conv_null_df.fillna(0, subset=[\"M2C\"]) \n",
    "                       .fillna(1, subset=[\"M3C\"]) \n",
    "                       .withColumn(\"Ratio\", col(\"M2C\") / col(\"M3C\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
